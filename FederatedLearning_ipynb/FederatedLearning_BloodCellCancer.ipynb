{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from typing import Dict\n",
        "import math\n",
        "from tqdm.std import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot\n",
        "import torch\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from typing import Tuple, List\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torchvision\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader,RandomSampler\n",
        "from sklearn.metrics import accuracy_score,recall_score,f1_score,precision_score,roc_auc_score\n",
        "from torchvision.transforms import transforms, ToTensor,Resize\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import glob\n",
        "import os.path as osp\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose,ToTensor,Resize,RandomErasing,RandomHorizontalFlip,RandomVerticalFlip\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "total_epochs= 10\n",
        "number_of_samples= 5\n",
        "learning_rate = 0.01\n",
        "numEpoch = 4\n",
        "batch_size = 32\n",
        "momentum = 0.9\n",
        "print_amount= 2\n",
        "\n",
        "class Net2nn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2nn, self).__init__()\n",
        "        self.fw= torchvision.models.efficientnet_b0(pretrained=False)\n",
        "        self.fw.features[0][0]=nn.Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "        self.fw.classifier[1]=nn.Sequential(\n",
        "            nn.Dropout(p=0.2, inplace=True),\n",
        "            nn.Linear(1280, 4),\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        return self.fw(x)\n",
        "\n",
        "def train(model, train_loader, criterion, device, optimizer):\n",
        "\n",
        "    model=model.to(device)\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    for data, target in tqdm(train_loader, desc=\"Training\"):\n",
        "        data,target = data.to(device),target.to(device)\n",
        "\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        prediction = output.argmax(dim=1, keepdim=True)\n",
        "        correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
        "\n",
        "    return train_loss / len(train_loader), correct/len(train_loader.dataset)\n",
        "\n",
        "def validation(\n",
        "    model: nn.Module,\n",
        "    test_loader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    device: torch.device,\n",
        "    relp: bool = False\n",
        ") -> Tuple[float, float, Tensor, Tensor, Tensor]:\n",
        "    \"\"\"\n",
        "    Validate the neural network model on test data.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The neural network model to validate.\n",
        "    - test_loader (DataLoader): The DataLoader for test data.\n",
        "    - criterion (nn.Module): The loss function.\n",
        "    - device (torch.device): The device to run the validation on.\n",
        "    - relp (bool): Flag to return predictions and scores.\n",
        "\n",
        "    Returns:\n",
        "    - Tuple containing test loss, accuracy, labels, predictions, and scores.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            score = torch.softmax(output, dim=1)\n",
        "            all_scores.append(score)\n",
        "            prediction = score[:,1]\n",
        "            all_preds.append(prediction)\n",
        "            all_labels.append(target)\n",
        "            threshold = 0.65\n",
        "            prediction_class = (prediction >= threshold).int()\n",
        "            correct += prediction_class.eq(target.int()).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = correct / len(test_loader.dataset)\n",
        "\n",
        "    if relp:\n",
        "        return test_loss, accuracy, torch.cat(all_labels, dim=0), torch.cat(all_preds, dim=0), torch.cat(all_scores, dim=0)\n",
        "    return test_loss, accuracy\n",
        "\n",
        "\n",
        "def validation(model, test_loader, criterion,relp=False):\n",
        "    model.eval()\n",
        "    model=model.to(device)\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    labels = []\n",
        "    preds= []\n",
        "    scores=[]\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "        # for data, target in tqdm(test_loader, desc=\"Testing\"):\n",
        "\n",
        "            data,target = data.to(device),target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            test_loss += criterion(output, target).item()\n",
        "            score=torch.softmax(output,dim=1)\n",
        "\n",
        "            scores.append(score)\n",
        "            prediction = output.argmax(dim=1, keepdim=True)\n",
        "            preds = preds + prediction.cpu().detach().tolist()\n",
        "            labels = labels + target.cpu().detach().tolist()\n",
        "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    correct /= len(test_loader.dataset)\n",
        "    if relp:\n",
        "        return (test_loss, correct, labels, preds,torch.cat(scores,dim=0).cpu().numpy())\n",
        "    return (test_loss, correct)\n",
        "\n",
        "\n",
        "def create_model_optimizer_criterion_dict(number_of_samples):\n",
        "    model_dict = dict()\n",
        "    optimizer_dict= dict()\n",
        "    criterion_dict = dict()\n",
        "\n",
        "    for i in range(number_of_samples):\n",
        "        model_name=\"model\"+str(i)\n",
        "        model_info=Net2nn()\n",
        "        model_dict.update({model_name : model_info })\n",
        "\n",
        "        optimizer_name=\"optimizer\"+str(i)\n",
        "        optimizer_info = torch.optim.SGD(model_info.parameters(), lr=learning_rate, momentum=momentum)\n",
        "        optimizer_dict.update({optimizer_name : optimizer_info })\n",
        "\n",
        "        criterion_name = \"criterion\"+str(i)\n",
        "        criterion_info = nn.CrossEntropyLoss()\n",
        "        criterion_dict.update({criterion_name : criterion_info})\n",
        "\n",
        "    return model_dict, optimizer_dict, criterion_dict\n",
        "\n",
        "\n",
        "def get_averaged_weights(main_model:nn.Module,model_dict:dict,number_of_samples:int):\n",
        "    state_dict={}\n",
        "    for name ,param in tqdm(main_model.state_dict().items()):\n",
        "        tmp_weights = torch.zeros(param.shape)\n",
        "        for i in range(number_of_samples):\n",
        "            tmp_weights = tmp_weights + model_dict['model'+str(i)].state_dict()[name].cpu()\n",
        "        tmp_weights = tmp_weights/number_of_samples\n",
        "        state_dict[name]= tmp_weights\n",
        "    main_model.load_state_dict(state_dict)\n",
        "\n",
        "def send_main_model_to_nodes_and_update_model_dict(main_model:torch.nn.Module, model_dict:Dict[str,nn.Module], number_of_samples):\n",
        "    for i in tqdm(range(number_of_samples)):\n",
        "        model_dict[\"model\"+str(i)].load_state_dict(main_model.state_dict())\n",
        "\n",
        "def start_train_end_node_process_without_print(number_of_samples):\n",
        "    for i in range (number_of_samples):\n",
        "\n",
        "        model=model_dict['model'+str(i)]\n",
        "        criterion=criterion_dict['criterion'+str(i)]\n",
        "        optimizer=optimizer_dict['optimizer'+str(i)]\n",
        "\n",
        "        for epoch in range(numEpoch):\n",
        "            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer)\n",
        "            test_loss, test_accuracy = validation(model, test_dl, criterion)\n",
        "\n",
        "def start_train_end_node_process_print_some(number_of_samples, print_amount, device):\n",
        "\n",
        "    for i in range (number_of_samples):\n",
        "\n",
        "        model=model_dict['model'+str(i)]\n",
        "        criterion=criterion_dict['criterion'+str(i)]\n",
        "        optimizer=optimizer_dict['optimizer'+str(i)]\n",
        "\n",
        "        if i<print_amount:\n",
        "            print(\"Subset\" ,i)\n",
        "\n",
        "        for epoch in range(numEpoch):\n",
        "\n",
        "            train_loss, train_accuracy = train(model, train_dl, criterion, device, optimizer)\n",
        "            test_loss, test_accuracy = validation(model, test_dl, criterion, device, relp=False)\n",
        "\n",
        "            if i<print_amount:\n",
        "                print(\"epoch: {:3.0f}\".format(epoch+1) + \" | train accuracy: {:7.5f}\".format(train_accuracy) + \" | test accuracy: {:7.5f}\".format(test_accuracy))\n",
        "\n",
        "class Data(Dataset):\n",
        "\n",
        "    def __init__(self,train=False) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.files1 = glob.glob('/content/bloodata/bloodata/BCC/benign/*.jpg', recursive=True)\n",
        "        self.files2 = glob.glob('/content/bloodata/bloodata/BCC/pre_b/*.jpg', recursive=True)\n",
        "        self.files3 = glob.glob('/content/bloodata/bloodata/BCC/pro_b/*.jpg', recursive=True)\n",
        "        self.files4 = glob.glob('/content/bloodata/bloodata/BCC/early_pre_b/*.jpg', recursive=True)\n",
        "\n",
        "        if train:\n",
        "            self.files1=self.files1[:int(len(self.files1)*0.8)]\n",
        "            self.files2=self.files2[:int(len(self.files2)*0.8)]\n",
        "            self.files3=self.files3[:int(len(self.files3)*0.8)]\n",
        "            self.files4=self.files4[:int(len(self.files4)*0.8)]\n",
        "            self.files = self.files1 + self.files2 + self.files3 + self.files4\n",
        "            self.transform = Compose([ToTensor(),Resize((50,50)),RandomVerticalFlip(),RandomErasing()])\n",
        "        else:\n",
        "            self.files1=self.files1[int(len(self.files1)*0.8):]\n",
        "            self.files2=self.files2[int(len(self.files2)*0.8):]\n",
        "            self.files3=self.files3[int(len(self.files3)*0.8):]\n",
        "            self.files4=self.files4[int(len(self.files4)*0.8):]\n",
        "\n",
        "            self.files = self.files1 + self.files2 + self.files3 + self.files4\n",
        "            self.transform = Compose([ToTensor(),Resize((50,50))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        file = self.files[index]\n",
        "        label = file.split('/')\n",
        "        if label[3] == 'benign':\n",
        "            label = 0\n",
        "        elif label[3] == 'pre_b':\n",
        "            label = 1\n",
        "        elif label[3] == 'pro_b':\n",
        "            label = 2\n",
        "        elif label[3] == 'early_pre_b':\n",
        "            label = 3\n",
        "        img = Image.open(file)\n",
        "\n",
        "        return self.transform(img),label\n",
        "\n",
        "def create_data_load(batch,drop_last,shuffle):\n",
        "    train_data=Data(train=True)\n",
        "    train_dataload = DataLoader(train_data,batch_size=batch,shuffle=shuffle,drop_last=drop_last)\n",
        "\n",
        "    test_data=Data(train=False)\n",
        "    test_dataload = DataLoader(test_data,batch_size=batch,shuffle=shuffle,drop_last=drop_last)\n",
        "\n",
        "    return train_dataload,test_dataload\n",
        "\n",
        "train_dl,valid_dl = create_data_load(batch_size,drop_last=True, shuffle=True)\n",
        "test_dl = valid_dl\n",
        "\n",
        "main_model = Net2nn()\n",
        "main_optimizer = torch.optim.SGD(main_model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "main_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_dict, optimizer_dict, criterion_dict = create_model_optimizer_criterion_dict(number_of_samples)\n",
        "\n",
        "send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score, accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compute_metrics(scores, labels, threshold=0.5):\n",
        "    fpr, tpr, _ = roc_curve(labels, scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    predictions = [int(score >= threshold) for score in scores]\n",
        "\n",
        "    p = precision_score(labels, predictions, average='macro')\n",
        "    r = recall_score(labels, predictions, average='macro')\n",
        "    f1 = f1_score(labels, predictions, average='macro')\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    return p, r, f1, acc, roc_auc\n",
        "start_train_end_node_process_print_some(number_of_samples, print_amount, device)\n",
        "\n",
        "get_averaged_weights(main_model,model_dict,number_of_samples)\n",
        "\n",
        "for epoch_ in range(total_epochs):\n",
        "    send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)\n",
        "    start_train_end_node_process_print_some(number_of_samples, print_amount)\n",
        "    get_averaged_weights(main_model,model_dict,number_of_samples)\n",
        "\n",
        "    test_loss, correct, label, preds, scores = validation(main_model, test_dl, main_criterion, device, relp=True)\n",
        "    p, r, f1, acc, roc_auc = compute_metrics(preds.cpu().numpy(), label.cpu().numpy(), threshold=0.65)\n",
        "    print(\"test_loss:\",test_loss)\n",
        "    print(f\"P: {p} | R: {r} | F1: {f1} | Acc: {acc} | AUC: {roc_auc}\")"
      ],
      "metadata": {
        "id": "7jou53j9-9d5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}